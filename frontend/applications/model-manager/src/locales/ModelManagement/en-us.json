{
  "ModelManagement": {
    "modelManager": "Model Manager",
    "llm": "LLM",
    "smallModel": "Small Model",
    "pleaseEnterTheModelName": "please enter the model name",
    "modelType": "Model Type",
    "sortByModelName": "Sort by model name",
    "sortByCreation": "Sort by creation",
    "sortByUpdate": "Sort by final operation time",
    "model_LLM": "Large Language Model(LLM)",
    "model_RLM": "​Reasoning Language Models​​(RLM)",
    "model_VU": "Visual Understanding(VU)",
    "testSuccessful": "Test connection successful",
    "tableColumns": {
      "modelName": "Model Name",
      "operation": "Operation",
      "menus": {
        "view": "View",
        "edit": "Edit",
        "delete": "Delete",
        "testConnection": "Test Connection",
        "authorizationManagement": "Authorization Management",
        "modelMonitoring": "Model Monitoring"
      },
      "modelType": "Model Type",
      "baseModel": "Base Model",
      "document": "Document",
      "maximumContext": "Maximum Context",
      "parameterQuantity": "Parameter Quantity",
      "creator": "Creator",
      "createdTime": "Created Time",
      "finalOperator": "Final Operator",
      "tokensCount": "Number of tokens",
      "unlimitedQuota": "Quota free",
      "in": "Enter",
      "out": "Output",
      "alreadyTokens": "Number of tokens used:",
      "remainingCounts": "Number of tokens remaining",
      "finalOperatedTime": "Final Operated Time"
    },
    "apiGuide": {
      "title": "API Guide",
      "arguments": "Arguments",
      "value": "Value",
      "copy": "Copy",
      "getAppId": "Get APP ID",
      "apiTitle": "The API uses an API format compatible with OpenAI. By modifying the configuration, you can use the OpenAI SDK or softwares compatible with the OpenAI API to access the API.",
      "initiateRequest": "Initiate Request",
      "method1": "Method 1: HTTP",
      "method1_2": "HTTP",
      "method2": " Method 2: SDK",
      "sdkDescribe1": "API is designed to be perfectly compatible with OpenAI's Python SDK and can be used with simple configuration.",
      "sdkDescribe2": "Install OpenAI SDK. Please make sure that the Python version used is at least 3.7.1 and the OpenAI SDK version is not less than 1.0.0.",
      "codeExample": "Code Example"
    },
    "modal": {
      "name_accessModel": "Access Model",
      "name_edit": "Edit",
      "name_view": "View",
      "testConnection": "Test Connection",
      "save": "Save",
      "cancel": "Cancel",
      "modelName": "model name",
      "baseModel": "base model",
      "modelType": "model type",
      "adaptationFile": "Adaptation file",
      "auth": "auth",
      "maximumContext": "maximum context",
      "parameterQuantity": "parameter quantity",
      "vectorDimension": "vector dimension",
      "batchSize": "Batch size",
      "maxNumberOfTokens": "Max number of tokens",
      "maxNumberOfDocuments": "Maximum number of documents",
      "batchSizeTip1": "Batch size refers to the maximum number of texts that can be processed in a single API call.",
      "batchSizeTip2": "For example, the batch size of text-embedding-v4 is 10, which means that a maximum of 10 texts can be passed in for vectorization in one request. This restriction applies to:",
      "batchSizeTip3": "String array input: The array can contain up to 10 elements.",
      "batchSizeTip4": "Text input: Text files can contain up to 10 lines of text.",
      "attentionUppercaseAndLowercase": "(When filling in fields, please pay attention to distinguishing between uppercase and lowercase letters)",
      "quotaTitle": "The model token uses quota function",
      "quotaTitleDescribe1": "- After enabling the function, you need to go to the [Quota Management] to allocate the upper limit of the usage limit of the model and assign the corresponding limit to the user.",
      "quotaTitleDescribe2": "- After disabling the function, there is no need to configure usage quotas, and all users can use it without restrictions.",
      "quotaTitleDescribe2_": "- After disabling the function, there is no need to configure usage quotas, and all users can use it without restrictions, And the system will automatically retain the credit limit records previously used by the user, but will reset the previously set 'credit limit rules' to zero."
    },
    "monitorDrawer": {
      "title": "Model Monitoring",
      "initialSpeed": "Time To First Token",
      "initialSpeedSub": "Measure the time taken from sending a request to generating the first word or token count",
      "outputSpeed": "Output Speed",
      "outputSpeedSub": "The number of output tokens per second, the higher the better",
      "tokenThroughput": "Token Throughput",
      "tokenThroughputSub": "The number of tokens generated per second for all requests, measured in tokens/s"
    }
  }
}
